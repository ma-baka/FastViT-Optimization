## 2025-11-19 (Day 1): 环境搭建与模型初步探索

### 1. 环境与数据排坑 (Setup & Debugging)
- **平台**: AutoDL (RTX 4090 D / 24GB VRAM)
- **环境修复**:
  - 解决 NumPy 2.x 与 PyTorch 1.11 不兼容报错，降级 NumPy。
  - 解决 DataLoader 报错：发现并删除了数据集中隐藏的 .ipynb_checkpoints 文件夹。
- **数据**: 成功配置 Imagenette (10类) 数据集。
- **工具**: 配置 GitHub SSH Key 实现代码同步；配置 .gitignore 过滤大文件。

### 2. 实验 A: 快速试错 (Baseline)
- **模型**: fastvit_t8 (Tiny版)
- **参数**: Batch Size 128, 从零训练 (Scratch)。
- **现象**:
  - 训练初期准确率极低 (~10%)。
  - **WandB 可视化**: 成功接入 WandB，观察到 train_loss 呈下降趋势，验证代码无 Bug，但模型收敛缓慢。

## 3. 实验 B: 性能压榨与模型升级 (Optimization)
- **模型**: `fastvit_ma36`
- **配置**: 
  - Batch Size: 64
  - Epochs: 100 + 10 (Cooldown)
  - 策略: 从零训练 (Training from Scratch)
- **最终结果 (Epoch 109)**:
  - **Top-1 准确率**: **87.18%**
  - **Top-5 准确率**: 98.73%
  - **Eval Loss**: 0.594
- **结果分析**:
  - 相比 T8 模型 (~10%) 提升巨大，证明了 MA36 架构在特征提取上的强悍能力。
  - 曲线显示在最后 10 个 Cooldown Epochs 阶段，准确率有显著拉升，证明移除数据增强后的微调策略非常有效。
  - `Eval Loss` (0.59) 远低于 `Train Loss` (1.60)，说明强数据增强（Mixup/Cutmix）有效防止了过拟合，模型泛化能力极强。
  
  
  ## 2025-11-20 (Day 2): 高光谱图像 (HSI) 迁移学习实验

### 1. 实验目标
- **任务**: 验证 FastViT 在高光谱图像 (Indian Pines) 上的分类性能。
- **核心对比**: 探究 "从零训练" (Scratch) 与 "加载 ImageNet 蒸馏预训练权重" (Fine-tuning) 的性能差异。

### 2. 实验数据集与预处理 (Dataset & Preprocessing)
- **数据集**: Indian Pines (IP)
  - **来源**: AVIRIS 传感器 (美国印第安纳州农业区)。
  - **规格**: 145x145 像素，20m 空间分辨率。
  - **波段**: 原始 200 有效波段 (光谱范围 0.4-2.5 µm)。
  - **类别**: 16 类地物 (主要是玉米、大豆等农作物)。
- **预处理策略**:
  - **降维**: 使用 PCA 将 200 波段压缩至 **3 主成分** (保留主要空间特征以适配 RGB 模型)。
  - **切片**: 采用 32x32 滑动窗口生成 Patch。
  - **划分**: 训练集/验证集 (80% / 20%)。

### 3. 实验结果对比

#### 实验 C: Baseline (从零训练)
- **实验名称**: PCAHSI
- **策略**: Scratch Training (无预训练)
- **最佳 Top-1 准确率**: 98.20%
- **最低 Eval Loss**: 0.335
- **结果分析**: 
  - 模型在训练前期 (Epoch 0-30) 收敛极其缓慢，存在明显的冷启动阶段。
  - 尽管最终精度尚可，但训练过程不稳定，依赖长周期的训练才能提取有效特征。

#### 实验 D: 迁移学习 (蒸馏权重)
- **实验名称**: PCAHSI_Fine-tuning
- **策略**: Fine-tuning (加载 ImageNet-1K 蒸馏权重)
- **最佳 Top-1 准确率**: 99.90%
- **最低 Eval Loss**: 0.216
- **结果分析**: 
  - **收敛速度极快**: 准确率曲线呈平滑上升趋势，无冷启动延迟。
  - **精度提升**: 相比 Baseline 提升了 1.7%，达到了近乎完美的 99.90%。
  - **结论**: 证明了 FastViT 在 ImageNet 上学到的纹理和空间特征，在经过 PCA 降维的高光谱数据上具有极强的迁移能力。


#### 实验 E: 挑战学术界标准 (1:9 极小样本划分)
- **实验名称**: PCAHSI_Fine-tuning_1_9
- **数据集划分**: 训练集 10% / 测试集 90% (符合 SpectralFormer 等 SOTA 论文标准)
- **策略**: Fine-tuning (加载 ImageNet 蒸馏权重)
- **最终结果 (Epoch 59)**:
  - **Top-1 准确率**: 30.02%
  - **Eval Loss**: 2.40 (仍呈快速下降趋势)
- **结果分析与重要发现**:
  1.  **精度骤降**: 相比 8:2 划分的 99.9%，在 1:9 划分下精度跌至 30%。这表明在极小样本情况下，仅靠 PCA 降维后的 3 通道空间特征已不足以支撑分类决策。
  2.  **欠拟合 (Underfitting)**: 训练/验证曲线在 Epoch 60 结束时仍处于陡峭上升期，未见收敛拐点。说明在样本极少时，模型需要更长的迭代周期来寻找最优解。
  3.  **光谱信息缺失**: PCA 将 200 波段压缩为 3 波段，丢失了关键的光谱指纹信息。在样本充足时(80%)模型可靠空间纹理“死记硬背”，但在样本稀缺时(10%)，光谱信息的缺失成为了致命瓶颈。


